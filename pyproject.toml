[project]
name = "lightspeed-evaluation"
version = "0.2.0"
description = "LSC Evaluation Framework - Comprehensive evaluation tooling for GenAI applications"
authors = []
requires-python = ">=3.11,<3.13"
readme = "README.md"
license = {text = "Apache"}

dependencies = [
    # Core evaluation framework dependencies
    "ragas>=0.3.0",
    "deepeval>=1.3.0",
    "litellm>=1.0.0",
    "pydantic>=2.0.0",
    "pyyaml>=6.0",
    "pandas>=2.1.4",
    "datasets>=2.0.0",
    "matplotlib>=3.5.0",
    "seaborn>=0.11.0",
    "numpy>=1.23.0",
    "torch==2.7.0",
    # Agent evaluation dependencies (for future integration)
    "httpx>=0.27.2",
    "tqdm>=4.67.1",
    # Generate answers dependencies
    "click>=8.0.0",
    "diskcache>=5.6.3",
    "tenacity>=9.1.2",
    "langchain[huggingface]>=0.3.27",
    "sentence-transformers>=5.1.0",
]

[dependency-groups]
dev = [
    "black>=25.1.0",
    "mypy>=1.15.0",
    "ruff>=0.8.0",
    "pyright>=1.1.401",
    "pydocstyle>=6.3.0",
    "pylint-pydantic>=0.3.0",
    "pytest>=8.3.2",
    "pytest-cov>=5.0.0",
    "pytest-mock>=3.15.1",
]

[project.scripts]
lightspeed-eval = "lightspeed_evaluation.runner.evaluation:main"
generate_answers = "generate_answers.generate_answers:main"

# Note: torch[cpu] variant configuration removed for uv compatibility
# Modern PyTorch versions are available on PyPI directly

[tool.black]
line-length = 88

[tool.pydocstyle]
convention = "google"

[tool.mypy]
disable_error_code = ["union-attr", "return-value", "arg-type", "import-untyped"]
ignore_missing_imports = true
plugins = ["pydantic.mypy"]

[tool.pydantic-mypy]
init_forbid_extra = true
init_typed = true
warn_required_dynamic_aliases = true

[tool.pylint.MASTER]
load-plugins = ["pylint_pydantic"]

[tool.ruff]
[tool.ruff.lint.flake8-tidy-imports]
banned-api = { "unittest" = { msg = "use pytest instead of unittest" }, "unittest.mock" = { msg = "use pytest-mock instead of unittest.mock" } }

[build-system]
requires = ["hatchling"]
build-backend = "hatchling.build"
[tool.hatch.build.targets.wheel]
packages = ["src/lightspeed_evaluation"]
